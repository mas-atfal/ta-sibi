{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pelatihan Model Klasifikasi Gambar Bahasa Isyarat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pengumpulan Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset untuk membuat model yang akan mengklasifikasikan gambar tangan (dari pergelangan tangan hingga per ujung jari) menjadi huruf alfabet dalam bahasa isyarat adalah [Sign Language MNIST](https://www.kaggle.com/datasets/datamunge/sign-language-mnist) diambil dari penyedia dataset MNIST lewat laman [Kaggle](https://www.kaggle.com). Dataset tersebut berisikan data latih yang berjumlah 27.455 dan data tes berjumlah 7172 yang keduanya memiliki label berupa angka dari 0-25 yang tiap angkanya secara berurutan mewakilkan huruf huruf alfabet dari A-Z kecuali huruf J dengan label 9 dan huruf z dengan label 25 dikarenakan huruf tersebut dalam bahasa isyarat menggunakan gestur, bukan gambar. Dataset [Sign Language MNIST](https://www.kaggle.com/datasets/datamunge/sign-language-mnist) berisikan gambar yang sudah diubah menjadi barisan bilangan bulat dalam format grayscale (tiap nilai pada larik/array yaitu 0-255) dengan ukuran 28x28 pixel dan format file berupa .csv dengan kolom berjumlah 785 dimulai dari \"label, pixel1, pixel2, pixel3...pixel784\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unduh dataset [Sign Language MNIST](https://www.kaggle.com/datasets/datamunge/sign-language-mnist) dari laman [Kaggle](https://www.kaggle.com) dan ekstrak file terkompresinya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muat Pakcage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mengunduh dataset, import semua package yang dibutuhkan untuk memproses data dan membuat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muat Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah memuat semua package yang dibutuhkan, maka buat variabel untuk memuat dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"sign_mnist_train/sign_mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"sign_mnist_test/sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dikarenakan dataset sudah terpisah antara data latih dan data tes, maka untuk menyiapkan variabel tersebut tidak diperlukan langkah tambahan dalam memisahkan data.\n",
    "Kemudian pisahkan antara label tidak data dengan data latih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "del train_df['label']\n",
    "del test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah memisahkan label dengan data inputan, label dengan bilangan positif yang mewakili tiap huruf (0-25 : A-Z) akan diubah menjadi larik/array.\n",
    "misal huruf \"A\" yang dilabeli dengan angka \"0\" akan diubah menjadi larik/array \n",
    "\n",
    "\"[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\"\n",
    "\n",
    " dan huruf \"B\" menjadi larik/array\n",
    " \n",
    " \"[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\" dan seterusnya sampai huruf terakhir.\n",
    " \n",
    " Proses ini disebut binerisasi label yang menghasilkan label dalam bentuk larik/array angka biner yang disebut \"One-Hot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke data latih dan data tes yang sudah dipisahkan dengan label, data tersebut berisi bilangan positif mulai dari 0-255 untuk tiap pixel gambar. Angka tersebut akan diubah dari rentang angka 0-255 menjadi 0-1 supaya mempermudah perhitungan dalam model. Proses ini dinamakan \"Normalization\" atau Normalisasi data inputan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.values\n",
    "x_test = test_df.values\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam melatih model, terutama yang akan digunakan adalah [pembelajaran mendalam / deep learning](https://www.dicoding.com/blog/mengenal-deep-learning/), prinsip yang bekerja adalah semakin banyak jumlah dan variasi data yang dilatih, maka semakin baik pula hasil prediksi dari sebuah model. Oleh karena itu, dataset saat ini akan diperbanyak/[augmentasi](https://blog.algorit.ma/augmentasi-data/) dengan rincian sebagai berikut.\n",
    "1. Secara random menambah variasi rotasi gambar/data dengan perubahan 10 derajat. [rotation_range=10]\n",
    "2. Secara random menambah variasi zoom gambar/data dengan perubahan 10%. [zoom_range=0.1]\n",
    "3. Secara random menambah variasi pergeseran gambar dari titik tengah secara horisontal sebesar 10% dari lebar gambar. [width_shift_range=0.1]\n",
    "4. Secara random menambah variasi pergeseran gambar dari titik tengah secara vertikal sebesar 10% dari tinggi gambar. [height_shift_range=0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perancangan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model yang akan digunakan adalah model deep learning dengan arsitektur [Convolutional Neural Network](https://medium.com/@16611110/apa-itu-convolutional-neural-network-836f70b193a4) atau bisa disingkat [CNN](https://medium.com/@16611110/apa-itu-convolutional-neural-network-836f70b193a4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding='same',\n",
    "          activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(25, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=24, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pelatihan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian melatih model dengan code dibawha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(x_train, y_train, batch_size = 128) ,epochs = 20 , validation_data = (x_test, y_test) , callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya menyimpan model yang sudah dilatih ke dalam sebuah file untuk digunakan di dalam aplikasi. Model disimpan dengan format keras model dengan ekstensi file .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
